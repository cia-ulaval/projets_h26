# Stochastic Gradient Descent, and Beyond! üìâ

## Fiche d'Identit√©

*   **Type de projet :** Publication scientifique
*   **Team Lead :** Benjamin Leblanc
*   **Partenaire Acad√©mique/Industriel :** N/A
*   **Effectif recherch√© :** 5 membres
*   **Profils recherch√©s :** Math√©matiques appliqu√©es, Probabilit√©s, Calcul int√©gral, Programmation Python

## Description du Projet

Vous √™tes-vous d√©j√† demand√© pourquoi votre mod√®le d'IA converge parfois vers une solution m√©diocre alors qu'il pourrait faire tellement mieux ? La r√©ponse se cache souvent dans l'algorithme d'optimisation.

La descente de gradient stochastique (SGD) est le moteur derri√®re l'entra√Ænement de pratiquement tous les mod√®les de deep learning. Pourtant, malgr√© 20 ans d'utilisation, cet algorithme reste imparfait : il se coince dans des minima locaux et rate souvent les meilleures solutions.

**Notre mission :** Comprendre pourquoi, et proposer une am√©lioration. Notre hypoth√®se ? Injecter du ¬´ bruit ¬ª intelligent dans le processus d'optimisation pourrait aider le mod√®le √† explorer de meilleures solutions.

Ce projet combine th√©orie math√©matique rigoureuse et exp√©rimentation pratique, avec un objectif concret : **publier nos r√©sultats dans une conf√©rence de type workshop**.

> üöÄ **Le projet est d√©j√† bien avanc√©** ‚Äî les avenues de recherche prometteuses sont identifi√©es et l'exploitation a commenc√©. Vous rejoignez une √©quipe en pleine action !

## Objectifs & Livrables

*   **Objectif Principal :** Soumettre un article de recherche dans une conf√©rence de type workshop.
*   **Livrables attendus :**
    *   Grille de recherche exhaustive sur l'injection optimale de bruit
    *   Exp√©rimentations sur des mod√®les d'envergure (classification d'images)
    *   Article scientifique pr√™t pour soumission

## Timeline Pr√©visionnelle de la Session

| Semaine | Activit√©/Phase |
| :-----: | :------------- |
| **1-3** | **Param√©trisation du bruit** ‚Äî Comment injecter le bruit de fa√ßon optimale ? |
| **4-6** | **Relation bruit/gradient** ‚Äî Trouver le bon √©quilibre entre bruit et estimations de gradient |
| **7-9** | **Exp√©rimentation √† grande √©chelle** ‚Äî Tests sur des vrais mod√®les de classification d'images |
| **10-12** | **R√©daction** ‚Äî Version pr√©liminaire de l'article |
| **12+** | **Finalisation & soumission** |

## Technologies & Comp√©tences Vis√©es

*   **Logiciels :** Python, PyTorch/TensorFlow, Jupyter, LaTeX
*   **Mat√©riels :** GPU (acc√®s fourni pour les exp√©rimentations)
*   **Comp√©tences :** Optimisation stochastique, th√©orie des probabilit√©s, r√©daction scientifique

## Pourquoi rejoindre ce projet ?

Vous allez aimer ce projet si :
*   Vous voulez comprendre ce qui se passe **vraiment** sous le capot du deep learning
*   L'id√©e de contribuer √† une **publication scientifique** vous attire
*   Vous aimez quand la th√©orie math√©matique rencontre la pratique
*   Vous cherchez un projet avec un **objectif concret et atteignable** cette session

## Pr√©requis

| R√¥le | Ce qu'on attend de toi |
|------|------------------------|
| Programmeur | Bases solides en Python |
| Th√©oricien | Notions en probabilit√©s et calcul int√©gral |

*Pas besoin d'√™tre expert ‚Äî la curiosit√© et la motivation comptent autant que les comp√©tences techniques !*

## Contact

*   **Team Lead :** Benjamin Leblanc
